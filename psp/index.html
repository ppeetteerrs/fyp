
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://ppeetteerrs.github.io/fyp/psp/">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.11">
    
    
      
        <title>psp - ct2cxr</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c5ef100.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.9647289d.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#psp.pSp" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="ct2cxr" class="md-header__button md-logo" aria-label="ct2cxr" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ct2cxr
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              psp
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ppeetteerrs/fyp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href=".." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../setup/" class="md-tabs__link">
      Setup
    </a>
  </li>

      
        
  
  


  
  
  
    

  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../notebooks/covid_ct/metadata/" class="md-tabs__link">
        Examples
      </a>
    </li>
  

  

  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../utils/" class="md-tabs__link md-tabs__link--active">
        API Reference
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="https://github.com/ppeetteerrs/fyp/issues" class="md-tabs__link">
      Report Issues
    </a>
  </li>

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="ct2cxr" class="md-nav__button md-logo" aria-label="ct2cxr" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    ct2cxr
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ppeetteerrs/fyp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../setup/" class="md-nav__link">
        Setup
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Examples" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1" data-md-state="indeterminate" type="checkbox" id="__nav_3_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1">
          Dataset
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Dataset" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          Dataset
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_1" data-md-state="indeterminate" type="checkbox" id="__nav_3_1_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_1">
          Covid-CT
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Covid-CT" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          Covid-CT
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/covid_ct/metadata/" class="md-nav__link">
        Parsed Metadata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/covid_ct/generate_dataset/" class="md-nav__link">
        Data Generation Process
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/covid_ct/view_lmdb/" class="md-nav__link">
        Generated LMDB Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/covid_ct/generate_drr/" class="md-nav__link">
        DeepDRR Generation
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_2" data-md-state="indeterminate" type="checkbox" id="__nav_3_1_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_2">
          LIDC
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="LIDC" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          LIDC
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/lidc/metadata/" class="md-nav__link">
        Parsed Metadata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/lidc/generate_dataset/" class="md-nav__link">
        Data Generation Process
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/lidc/view_lmdb/" class="md-nav__link">
        Generated LMDB Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../notebooks/lidc/generate_drr/" class="md-nav__link">
        DeepDRR Generation
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        utils
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          psp
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        psp
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#psp.pSp" class="md-nav__link">
    pSp
  </a>
  
    <nav class="md-nav" aria-label="pSp">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.pSp.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.pSp.mix_codes" class="md-nav__link">
    mix_codes()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#psp.encoder" class="md-nav__link">
    encoder
  </a>
  
    <nav class="md-nav" aria-label="encoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.DownsampleBlock" class="md-nav__link">
    DownsampleBlock
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.Encoder" class="md-nav__link">
    Encoder
  </a>
  
    <nav class="md-nav" aria-label="Encoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.Encoder.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.Encoder.upsample_add" class="md-nav__link">
    upsample_add()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.ResnetBlock" class="md-nav__link">
    ResnetBlock
  </a>
  
    <nav class="md-nav" aria-label="ResnetBlock">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.ResnetBlock.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.SEModule" class="md-nav__link">
    SEModule
  </a>
  
    <nav class="md-nav" aria-label="SEModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.SEModule.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.ToStyle" class="md-nav__link">
    ToStyle
  </a>
  
    <nav class="md-nav" aria-label="ToStyle">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.ToStyle.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#psp.loss" class="md-nav__link">
    loss
  </a>
  
    <nav class="md-nav" aria-label="loss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.loss.IDLoss" class="md-nav__link">
    IDLoss
  </a>
  
    <nav class="md-nav" aria-label="IDLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.loss.IDLoss.extract_feats" class="md-nav__link">
    extract_feats()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.loss.IDLoss.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.loss.RegLoss" class="md-nav__link">
    RegLoss
  </a>
  
    <nav class="md-nav" aria-label="RegLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.loss.RegLoss.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#psp.ranger" class="md-nav__link">
    ranger
  </a>
  
    <nav class="md-nav" aria-label="ranger">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.ranger.Ranger" class="md-nav__link">
    Ranger
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/ppeetteerrs/fyp/issues" class="md-nav__link">
        Report Issues
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#psp.pSp" class="md-nav__link">
    pSp
  </a>
  
    <nav class="md-nav" aria-label="pSp">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.pSp.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.pSp.mix_codes" class="md-nav__link">
    mix_codes()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#psp.encoder" class="md-nav__link">
    encoder
  </a>
  
    <nav class="md-nav" aria-label="encoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.DownsampleBlock" class="md-nav__link">
    DownsampleBlock
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.Encoder" class="md-nav__link">
    Encoder
  </a>
  
    <nav class="md-nav" aria-label="Encoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.Encoder.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.Encoder.upsample_add" class="md-nav__link">
    upsample_add()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.ResnetBlock" class="md-nav__link">
    ResnetBlock
  </a>
  
    <nav class="md-nav" aria-label="ResnetBlock">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.ResnetBlock.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.SEModule" class="md-nav__link">
    SEModule
  </a>
  
    <nav class="md-nav" aria-label="SEModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.SEModule.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.encoder.ToStyle" class="md-nav__link">
    ToStyle
  </a>
  
    <nav class="md-nav" aria-label="ToStyle">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.encoder.ToStyle.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#psp.loss" class="md-nav__link">
    loss
  </a>
  
    <nav class="md-nav" aria-label="loss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.loss.IDLoss" class="md-nav__link">
    IDLoss
  </a>
  
    <nav class="md-nav" aria-label="IDLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.loss.IDLoss.extract_feats" class="md-nav__link">
    extract_feats()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.loss.IDLoss.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#psp.loss.RegLoss" class="md-nav__link">
    RegLoss
  </a>
  
    <nav class="md-nav" aria-label="RegLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.loss.RegLoss.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#psp.ranger" class="md-nav__link">
    ranger
  </a>
  
    <nav class="md-nav" aria-label="ranger">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#psp.ranger.Ranger" class="md-nav__link">
    Ranger
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


  <h1>psp</h1>

<div class="doc doc-object doc-module">


    <div class="doc doc-contents first">




  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h2 id="psp.pSp" class="doc doc-heading">
          <code>pSp</code>



</h2>
<div class="highlight"><pre><span></span><code><span class="n">pSp</span><span class="p">(</span>
    <span class="n">ckpt</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">use_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">e_in_channel</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">e_resolution</span><span class="p">:</span> <span class="n">Resolution</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
    <span class="n">g_resolution</span><span class="p">:</span> <span class="n">Resolution</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
    <span class="n">g_latent_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
    <span class="n">g_n_mlp</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">g_lr_mlp_mult</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="n">g_channels</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Resolution</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">default_channels</span><span class="p">,</span>
    <span class="n">g_blur_kernel</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
        <p class="doc doc-class-bases">
          Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>




      <p>pSp module. Consists of an encoder and a pretrained StyleGAN generator.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>ckpt</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Any">Any</span>]</code>
          </td>
          <td><p>PyTorch checkpoint dictionary. Can be pretrained StyleGAN or pSp.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>use_mean</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>Add latent average to generated style vectors.</p></td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>e_in_channel</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Encoder in_channel.</p></td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>e_resolution</code></td>
          <td>
                <code><span title="stylegan2_torch.Resolution">Resolution</span></code>
          </td>
          <td><p>Encoder resolution.</p></td>
          <td>
                <code>256</code>
          </td>
        </tr>
        <tr>
          <td><code>g_resolution</code></td>
          <td>
                <code><span title="stylegan2_torch.Resolution">Resolution</span></code>
          </td>
          <td><p>Generator resolution.</p></td>
          <td>
                <code>256</code>
          </td>
        </tr>
        <tr>
          <td><code>g_latent_dim</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Generator latent dimension.</p></td>
          <td>
                <code>512</code>
          </td>
        </tr>
        <tr>
          <td><code>g_n_mlp</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Generator mapping network layers.</p></td>
          <td>
                <code>8</code>
          </td>
        </tr>
        <tr>
          <td><code>g_lr_mlp_mult</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>Generator mapping network lr multiplier.</p></td>
          <td>
                <code>0.01</code>
          </td>
        </tr>
        <tr>
          <td><code>g_channels</code></td>
          <td>
                <code><span title="typing.Dict">Dict</span>[<span title="stylegan2_torch.Resolution">Resolution</span>, int]</code>
          </td>
          <td><p>Generator no. of channels at each resolution level.</p></td>
          <td>
                <code>default_channels</code>
          </td>
        </tr>
        <tr>
          <td><code>g_blur_kernel</code></td>
          <td>
                <code><span title="typing.List">List</span>[int]</code>
          </td>
          <td><p>Generator blurring kernel.</p></td>
          <td>
                <code>[1, 3, 3, 1]</code>
          </td>
        </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>psp/__init__.py</code></summary>
              <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">ckpt</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">use_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">e_in_channel</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">e_resolution</span><span class="p">:</span> <span class="n">Resolution</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
    <span class="n">g_resolution</span><span class="p">:</span> <span class="n">Resolution</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
    <span class="n">g_latent_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
    <span class="n">g_n_mlp</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">g_lr_mlp_mult</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="n">g_channels</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Resolution</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">default_channels</span><span class="p">,</span>
    <span class="n">g_blur_kernel</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    pSp module. Consists of an encoder and a pretrained StyleGAN generator.</span>

<span class="sd">    Args:</span>
<span class="sd">        ckpt (Dict[str, Any]): PyTorch checkpoint dictionary. Can be pretrained StyleGAN or pSp.</span>
<span class="sd">        use_mean (bool, optional): Add latent average to generated style vectors.</span>
<span class="sd">        e_in_channel (int, optional): Encoder in_channel.</span>
<span class="sd">        e_resolution (Resolution, optional): Encoder resolution.</span>
<span class="sd">        g_resolution (Resolution, optional): Generator resolution.</span>
<span class="sd">        g_latent_dim (int, optional): Generator latent dimension.</span>
<span class="sd">        g_n_mlp (int, optional): Generator mapping network layers.</span>
<span class="sd">        g_lr_mlp_mult (float, optional): Generator mapping network lr multiplier.</span>
<span class="sd">        g_channels (Dict[Resolution, int], optional): Generator no. of channels at each resolution level.</span>
<span class="sd">        g_blur_kernel (List[int], optional): Generator blurring kernel.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># Define architecture</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">in_channel</span><span class="o">=</span><span class="n">e_in_channel</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">e_resolution</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
        <span class="s2">&quot;cuda&quot;</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span>
        <span class="n">resolution</span><span class="o">=</span><span class="n">g_resolution</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="o">=</span><span class="n">g_latent_dim</span><span class="p">,</span>
        <span class="n">n_mlp</span><span class="o">=</span><span class="n">g_n_mlp</span><span class="p">,</span>
        <span class="n">lr_mlp_mult</span><span class="o">=</span><span class="n">g_lr_mlp_mult</span><span class="p">,</span>
        <span class="n">channels</span><span class="o">=</span><span class="n">g_channels</span><span class="p">,</span>
        <span class="n">blur_kernel</span><span class="o">=</span><span class="n">g_blur_kernel</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="c1"># Load model checkpoints. Resumed flag indicates whether pSp is pretrained.</span>
    <span class="k">if</span> <span class="s2">&quot;g_ema&quot;</span> <span class="ow">in</span> <span class="n">ckpt</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;g_ema&quot;</span><span class="p">],</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resumed</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;encoder&quot;</span><span class="p">],</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;decoder&quot;</span><span class="p">],</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resumed</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Load latent average</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">latent_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">use_mean</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;latent_avg&quot;</span> <span class="ow">in</span> <span class="n">ckpt</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">latent_avg</span> <span class="o">=</span> <span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;latent_avg&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">latent_avg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">mean_latent</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_avg</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div>
</td></tr></table>
            </details>



  <div class="doc doc-children">












  <div class="doc doc-object doc-function">



<h3 id="psp.pSp.forward" class="doc doc-heading">
forward


</h3>
<div class="highlight"><pre><span></span><code><span class="n">forward</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]],</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;encode&quot;</span><span class="p">,</span> <span class="s2">&quot;generate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;generate&quot;</span><span class="p">,</span>
    <span class="n">mix_mode</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;alt&quot;</span><span class="p">,</span> <span class="s2">&quot;half&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>Performs forward propagation. Task can be encode or generate.</p>
<p><code>encode</code> returns the style vectors <code>Tensor</code>.</p>
<p><code>generate</code> returns a <code>Tuple[Tensor, Tensor]</code> of generated image and style vectors.</p>
<p><code>mix_mode</code> determines the mixing method when input contains more than 1 image.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>input</code></td>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="torch.Tensor">Tensor</span>, <span title="typing.Tuple">Tuple</span>[<span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>]]</code>
          </td>
          <td><p>Input image(s).</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>task</code></td>
          <td>
                <code><span title="typing.Literal">Literal</span>[&#39;encode&#39;, &#39;generate&#39;]</code>
          </td>
          <td><p>pSp forward task.</p></td>
          <td>
                <code>&#39;generate&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>mix_mode</code></td>
          <td>
                <code><span title="typing.Literal">Literal</span>[&#39;alt&#39;, &#39;half&#39;, &#39;mean&#39;]</code>
          </td>
          <td><p>Mixing mode if input contains 2 images.</p></td>
          <td>
                <code>&#39;mean&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>NotImplementedError</code>
          </td>
          <td><p><em>description</em></p></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.Union">Union</span>[<span title="torch.Tensor">Tensor</span>, <span title="typing.Tuple">Tuple</span>[<span title="torch.Tensor">Tensor</span>, <span title="torch.Tensor">Tensor</span>]]</code>
          </td>
          <td><p>Union[Tensor, Tuple[Tensor, Tensor]]: <em>description</em></p></td>
        </tr>
    </tbody>
  </table>

        <details class="quote">
          <summary>Source code in <code>psp/__init__.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]],</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;encode&quot;</span><span class="p">,</span> <span class="s2">&quot;generate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;generate&quot;</span><span class="p">,</span>
    <span class="n">mix_mode</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;alt&quot;</span><span class="p">,</span> <span class="s2">&quot;half&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs forward propagation. Task can be encode or generate.</span>

<span class="sd">    `encode` returns the style vectors `Tensor`.</span>

<span class="sd">    `generate` returns a `Tuple[Tensor, Tensor]` of generated image and style vectors.</span>

<span class="sd">    `mix_mode` determines the mixing method when input contains more than 1 image.</span>

<span class="sd">    Args:</span>
<span class="sd">        input (Union[Tensor, Tuple[Tensor, Tensor]]): Input image(s).</span>
<span class="sd">        task (Literal[&quot;encode&quot;, &quot;generate&quot;], optional): pSp forward task.</span>
<span class="sd">        mix_mode (Literal[&quot;alt&quot;, &quot;half&quot;, &quot;mean&quot;], optional): Mixing mode if input contains 2 images.</span>

<span class="sd">    Raises:</span>
<span class="sd">        NotImplementedError: _description_</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[Tensor, Tuple[Tensor, Tensor]]: _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Mix if two inputs</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">codes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">codes1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">codes2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">codes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mix_codes</span><span class="p">(</span><span class="n">codes1</span><span class="p">,</span> <span class="n">codes2</span><span class="p">,</span> <span class="n">mix_mode</span><span class="o">=</span><span class="n">mix_mode</span><span class="p">)</span>

    <span class="c1"># Add latent average if needed</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_avg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">codes</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_avg</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">codes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Skip image generation if task is encode</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;encode&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">codes</span>
    <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;generate&quot;</span><span class="p">:</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
            <span class="p">[</span><span class="n">codes</span><span class="p">],</span> <span class="n">return_latents</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">input_type</span><span class="o">=</span><span class="s2">&quot;w_plus&quot;</span><span class="p">,</span> <span class="n">noises</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pSp task </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2"> not implemented.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">codes</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="psp.pSp.mix_codes" class="doc doc-heading">
mix_codes

  <span class="doc doc-properties">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

</h3>
<div class="highlight"><pre><span></span><code><span class="n">mix_codes</span><span class="p">(</span>
    <span class="n">codes1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">codes2</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mix_mode</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;alt&quot;</span><span class="p">,</span> <span class="s2">&quot;half&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>Mixes two latent vectors.</p>
<p><code>alt</code>: Alternates between each latent vector.
<code>half</code>: Takes first half from codes1 and next half from codes2.
<code>mean</code>: Takes the mean of the latent vectors.</p>

        <details class="quote">
          <summary>Source code in <code>psp/__init__.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">mix_codes</span><span class="p">(</span>
    <span class="n">codes1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">codes2</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mix_mode</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;alt&quot;</span><span class="p">,</span> <span class="s2">&quot;half&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mixes two latent vectors.</span>

<span class="sd">    `alt`: Alternates between each latent vector.</span>
<span class="sd">    `half`: Takes first half from codes1 and next half from codes2.</span>
<span class="sd">    `mean`: Takes the mean of the latent vectors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mix_mode</span> <span class="o">==</span> <span class="s2">&quot;alt&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">codes1</span><span class="p">[:,</span> <span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">codes2</span><span class="p">[:,</span> <span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">codes1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">],</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">mix_mode</span> <span class="o">==</span> <span class="s2">&quot;half&quot;</span><span class="p">:</span>
        <span class="n">idx_half</span> <span class="o">=</span> <span class="n">codes1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">codes1</span><span class="p">[:,</span> <span class="p">:</span><span class="n">idx_half</span><span class="p">,</span> <span class="p">:],</span> <span class="n">codes2</span><span class="p">[:,</span> <span class="n">idx_half</span><span class="p">:,</span> <span class="p">:]],</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">mix_mode</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">codes1</span> <span class="o">+</span> <span class="n">codes2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mixing mode </span><span class="si">{</span><span class="n">mix_mode</span><span class="si">}</span><span class="s2"> not implemented.&quot;</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>





  <div class="doc doc-object doc-module">



<h2 id="psp.encoder" class="doc doc-heading">
        <code>encoder</code>



</h2>

    <div class="doc doc-contents ">

      <p>pSp encoder module</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h3 id="psp.encoder.DownsampleBlock" class="doc doc-heading">
          <code>DownsampleBlock</code>



</h3>
<div class="highlight"><pre><span></span><code><span class="n">DownsampleBlock</span><span class="p">(</span>
    <span class="n">in_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">out_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">down_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
        <p class="doc doc-class-bases">
          Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Sequential">Sequential</span></code></p>




      <p>ResNet blocks for a given resolution (downsample then same resolution).
It will contain 1 <code>in_channel to out_channel</code> ResNet block that downsamples the input features maps
follwoed by n-1 <code>out_channel to out_channel</code> ResNet blocks of the same resolution.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_channel</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Number of input channels</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>out_channel</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Number of output channels</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>n_layers</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Number of ResNet blocks</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>down_factor</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Downsampling factor. Defaults to 2.</p></td>
          <td>
                <code>2</code>
          </td>
        </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>psp/encoder.py</code></summary>
              <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">down_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ResNet blocks for a given resolution (downsample then same resolution).</span>
<span class="sd">    It will contain 1 `in_channel to out_channel` ResNet block that downsamples the input features maps</span>
<span class="sd">    follwoed by n-1 `out_channel to out_channel` ResNet blocks of the same resolution.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_channel (int): Number of input channels</span>
<span class="sd">        out_channel (int): Number of output channels</span>
<span class="sd">        n_layers (int): Number of ResNet blocks</span>
<span class="sd">        down_factor (int, optional): Downsampling factor. Defaults to 2.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">ResnetBlock</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">down_factor</span><span class="p">),</span>
        <span class="o">*</span><span class="p">[</span><span class="n">ResnetBlock</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)],</span>
    <span class="p">)</span>
</code></pre></div>
</td></tr></table>
            </details>



  <div class="doc doc-children">










  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h3 id="psp.encoder.Encoder" class="doc doc-heading">
          <code>Encoder</code>



</h3>
<div class="highlight"><pre><span></span><code><span class="n">Encoder</span><span class="p">(</span><span class="n">in_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">resolution</span><span class="p">:</span> <span class="n">Resolution</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
        <p class="doc doc-class-bases">
          Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>




      <p>pSp encoder (feature pyramid with ResNet backbone + feature-to-style maps).</p>

<details class="info">
  <summary>Info</summary>
  <p>For face similarity measurement, the SOTA progress is <code>SphereFace</code> =&gt; <code>CosFace</code> =&gt; <code>ArcFace</code>.
SphereFace proposed a <a href="https://arxiv.org/pdf/1704.08063.pdf">CNN architecture</a> (Table 2) slightly different from ResNet.
They are also the ones who suggested using <code>PReLU</code> instead of <code>ReLU</code>.</p>
<p>From SpherFace's <a href="https://github.com/wy1iu/sphereface/search?p=2&amp;q=prelu">github</a>:</p>
<blockquote>
<p>In SphereFace, our network architecures use residual units as building blocks, but are quite different from the standrad ResNets (e.g., BatchNorm is not used, the prelu replaces the relu, different initializations, etc). We proposed 4-layer, 20-layer, 36-layer and 64-layer architectures for face recognition</p>
</blockquote>
<p>Standard ResNets use bottleneck archiecture from ResNet50 onwards, so they would have 3 layers for each of the <code>[3, 4, 6, 3]</code> ResNet blocks. This <a href="https://github.com/ronghuaiyang/arcface-pytorch/blob/master/models/resnet.py">implementation</a> follows that (just like original <a href="https://github.com/tornadomeet/ResNet/blob/master/train_resnet.py">ResNet</a>). But <a href="https://github.com/deepinsight/insightface/blob/8b79096e70a10a4899f1ce59882ea4d56e634d40/recognition/arcface_mxnet/symbol/fresnet.py#L1175">ArcFace's MXNet</a> did not use bottleneck so that have 2 layers per block, thus the use of <code>[3, 4, 14, 3]</code>. There is this convention to add additional blocks to <code>conv4_x</code>, forgot where that came from (SphereFace or ResNet)?</p>
</details>
  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>in_channel</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p><em>description</em></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>resolution</code></td>
          <td>
                <code><span title="stylegan2_torch.Resolution">Resolution</span></code>
          </td>
          <td><p><em>description</em></p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>psp/encoder.py</code></summary>
              <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">resolution</span><span class="p">:</span> <span class="n">Resolution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    pSp encoder (feature pyramid with ResNet backbone + feature-to-style maps).</span>

<span class="sd">    Info:</span>
<span class="sd">        For face similarity measurement, the SOTA progress is `SphereFace` =&gt; `CosFace` =&gt; `ArcFace`.</span>
<span class="sd">        SphereFace proposed a [CNN architecture](https://arxiv.org/pdf/1704.08063.pdf) (Table 2) slightly different from ResNet.</span>
<span class="sd">        They are also the ones who suggested using `PReLU` instead of `ReLU`.</span>

<span class="sd">        From SpherFace&#39;s [github](https://github.com/wy1iu/sphereface/search?p=2&amp;q=prelu):</span>
<span class="sd">        &gt; In SphereFace, our network architecures use residual units as building blocks, but are quite different from the standrad ResNets (e.g., BatchNorm is not used, the prelu replaces the relu, different initializations, etc). We proposed 4-layer, 20-layer, 36-layer and 64-layer architectures for face recognition</span>

<span class="sd">        Standard ResNets use bottleneck archiecture from ResNet50 onwards, so they would have 3 layers for each of the `[3, 4, 6, 3]` ResNet blocks. This [implementation](https://github.com/ronghuaiyang/arcface-pytorch/blob/master/models/resnet.py) follows that (just like original [ResNet]( https://github.com/tornadomeet/ResNet/blob/master/train_resnet.py)). But [ArcFace&#39;s MXNet](https://github.com/deepinsight/insightface/blob/8b79096e70a10a4899f1ce59882ea4d56e634d40/recognition/arcface_mxnet/symbol/fresnet.py#L1175) did not use bottleneck so that have 2 layers per block, thus the use of `[3, 4, 14, 3]`. There is this convention to add additional blocks to `conv4_x`, forgot where that came from (SphereFace or ResNet)?</span>

<span class="sd">    Args:</span>
<span class="sd">        in_channel (int): _description_</span>
<span class="sd">        resolution (Resolution): _description_</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span>
        <span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
        <span class="n">PReLU</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Backbone</span>
    <span class="c1"># self.block_N means output from block is of size N x N</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">block_128</span> <span class="o">=</span> <span class="n">DownsampleBlock</span><span class="p">(</span><span class="n">in_channel</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channel</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">block_64</span> <span class="o">=</span> <span class="n">DownsampleBlock</span><span class="p">(</span><span class="n">in_channel</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channel</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">block_32</span> <span class="o">=</span> <span class="n">DownsampleBlock</span><span class="p">(</span><span class="n">in_channel</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_channel</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">block_16</span> <span class="o">=</span> <span class="n">DownsampleBlock</span><span class="p">(</span><span class="n">in_channel</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_channel</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Feature-style maps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coarse_map</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">ToStyle</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mid_map</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">ToStyle</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fine_map</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
        <span class="n">ToStyle</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">resolution</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">7</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Feature pyramid up-channelling (I doubt the use of the lateral layer)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lateral_32</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lateral_64</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
            </details>



  <div class="doc doc-children">


















  <div class="doc doc-object doc-function">



<h4 id="psp.encoder.Encoder.forward" class="doc doc-heading">
forward


</h4>
<div class="highlight"><pre><span></span><code><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>Converts input <code>x</code> into <span class="arithmatex">\(W+\)</span> style vectors</p>

        <details class="quote">
          <summary>Source code in <code>psp/encoder.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts input `x` into $W+$ style vectors</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">feature_64</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_64</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">block_128</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">feature_32</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_32</span><span class="p">(</span><span class="n">feature_64</span><span class="p">)</span>
    <span class="n">feature_16</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_16</span><span class="p">(</span><span class="n">feature_32</span><span class="p">)</span>

    <span class="n">latents</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">latents</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">feature_16</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coarse_map</span><span class="p">)</span>

    <span class="n">combined_32</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsample_add</span><span class="p">(</span><span class="n">feature_16</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lateral_32</span><span class="p">(</span><span class="n">feature_32</span><span class="p">))</span>
    <span class="n">latents</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">combined_32</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mid_map</span><span class="p">)</span>

    <span class="n">combined_64</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsample_add</span><span class="p">(</span><span class="n">combined_32</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lateral_64</span><span class="p">(</span><span class="n">feature_64</span><span class="p">))</span>
    <span class="n">latents</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">combined_64</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fine_map</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">latents</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h4 id="psp.encoder.Encoder.upsample_add" class="doc doc-heading">
upsample_add


</h4>
<div class="highlight"><pre><span></span><code><span class="n">upsample_add</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>Adds <code>x</code> to <code>y</code> after bilinear upsampling.</p>

        <details class="quote">
          <summary>Source code in <code>psp/encoder.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">upsample_add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adds `x` to `y` after bilinear upsampling.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="n">y</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h3 id="psp.encoder.ResnetBlock" class="doc doc-heading">
          <code>ResnetBlock</code>



</h3>
<div class="highlight"><pre><span></span><code><span class="n">ResnetBlock</span><span class="p">(</span><span class="n">in_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
        <p class="doc doc-class-bases">
          Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>




      <p>Non-standard ResNet block used by pSp.</p>

<details class="warning">
  <summary>Warning</summary>
  <p>pSp's ResNet implementation is a mess. This ResNetBlock is copied from <a href="https://github.com/TreB1eN/InsightFace_Pytorch">TreB1eN</a>'s implementation of <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Deng_ArcFace_Additive_Angular_Margin_Loss_for_Deep_Face_Recognition_CVPR_2019_paper.pdf">ArcFace</a>'s ResNet because ArcFace's source code was written in MXNet (sorry but why?!).</p>
<p>There are some differences between TreB1eN's implementation and the MXNet as shown <a href="https://github.com/TreB1eN/InsightFace_Pytorch/issues/37">here</a>. The <code>MaxPool</code> shortcut is probably taken from <a href="https://arxiv.org/pdf/2004.04989.pdf">here</a>.</p>
</details>
            <details class="quote">
              <summary>Source code in <code>psp/encoder.py</code></summary>
              <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Non-standard ResNet block used by pSp.</span>

<span class="sd">    Warning:</span>
<span class="sd">        pSp&#39;s ResNet implementation is a mess. This ResNetBlock is copied from [TreB1eN](https://github.com/TreB1eN/InsightFace_Pytorch)&#39;s implementation of [ArcFace](https://openaccess.thecvf.com/content_CVPR_2019/papers/Deng_ArcFace_Additive_Angular_Margin_Loss_for_Deep_Face_Recognition_CVPR_2019_paper.pdf)&#39;s ResNet because ArcFace&#39;s source code was written in MXNet (sorry but why?!).</span>

<span class="sd">        There are some differences between TreB1eN&#39;s implementation and the MXNet as shown [here](https://github.com/TreB1eN/InsightFace_Pytorch/issues/37). The `MaxPool` shortcut is probably taken from [here](https://arxiv.org/pdf/2004.04989.pdf).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">in_channel</span> <span class="o">==</span> <span class="n">out_channel</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shortcut</span> <span class="o">=</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shortcut</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span>
            <span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="p">),</span>
            <span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channel</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span>
        <span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">),</span>
        <span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">PReLU</span><span class="p">(</span><span class="n">out_channel</span><span class="p">),</span>
        <span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channel</span><span class="p">),</span>
        <span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channel</span><span class="p">),</span>
        <span class="n">SEModule</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
    <span class="p">)</span>
</code></pre></div>
</td></tr></table>
            </details>



  <div class="doc doc-children">










  <div class="doc doc-object doc-function">



<h4 id="psp.encoder.ResnetBlock.forward" class="doc doc-heading">
forward


</h4>
<div class="highlight"><pre><span></span><code><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>One ResNet block forward propagation.</p>

        <details class="quote">
          <summary>Source code in <code>psp/encoder.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    One ResNet block forward propagation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shortcut</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h3 id="psp.encoder.SEModule" class="doc doc-heading">
          <code>SEModule</code>



</h3>
<div class="highlight"><pre><span></span><code><span class="n">SEModule</span><span class="p">(</span><span class="n">channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">reduction</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
        <p class="doc doc-class-bases">
          Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>




      <p>Squeeze and Excitation Block</p>

<details class="info">
  <summary>Info</summary>
  <p>SEModule adopts a bottleneck architecture (reduce then restore) to increase computational efficiency.
SEModule incorporates global information when scaling feature maps (e.g. dealing with relative means).
<a href="https://amaarora.github.io/2020/07/24/SeNet.html#intuition-behind-squeeze-and-excitation-networks">Reference</a></p>
</details>
            <details class="quote">
              <summary>Source code in <code>psp/encoder.py</code></summary>
              <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">reduction</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Squeeze and Excitation Block</span>

<span class="sd">    Info:</span>
<span class="sd">        SEModule adopts a bottleneck architecture (reduce then restore) to increase computational efficiency.</span>
<span class="sd">        SEModule incorporates global information when scaling feature maps (e.g. dealing with relative means).</span>
<span class="sd">        [Reference](https://amaarora.github.io/2020/07/24/SeNet.html#intuition-behind-squeeze-and-excitation-networks)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">se</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="c1"># Can replace with global avg pool</span>
        <span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="c1"># Can just use normal linear</span>
        <span class="n">Conv2d</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">channel</span> <span class="o">//</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">Conv2d</span><span class="p">(</span><span class="n">channel</span> <span class="o">//</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">Sigmoid</span><span class="p">(),</span>
    <span class="p">)</span>
</code></pre></div>
</td></tr></table>
            </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-function">



<h4 id="psp.encoder.SEModule.forward" class="doc doc-heading">
forward


</h4>
<div class="highlight"><pre><span></span><code><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>Performs squeeze and excitation.</p>

        <details class="quote">
          <summary>Source code in <code>psp/encoder.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs squeeze and excitation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">input</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">se</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h3 id="psp.encoder.ToStyle" class="doc doc-heading">
          <code>ToStyle</code>



</h3>
<div class="highlight"><pre><span></span><code><span class="n">ToStyle</span><span class="p">(</span><span class="n">in_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">resolution</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
        <p class="doc doc-class-bases">
          Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>




      <p>Maps feature map to <span class="arithmatex">\(W+\)</span> style vector through a series of downsampling convolutions + LeakyReLU.</p>

            <details class="quote">
              <summary>Source code in <code>psp/encoder.py</code></summary>
              <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">resolution</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Maps feature map to $W+$ style vector through a series of downsampling convolutions + LeakyReLU.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">out_channel</span> <span class="o">=</span> <span class="n">out_channel</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">resolution</span> <span class="o">=</span> <span class="n">resolution</span>
    <span class="n">modules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">resolution</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">modules</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
        <span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">)</span>
    <span class="c1"># Why suddenly equalized learning rate?!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">EqualLinear</span><span class="p">(</span><span class="n">out_channel</span><span class="p">,</span> <span class="n">out_channel</span><span class="p">,</span> <span class="n">lr_mult</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
            </details>



  <div class="doc doc-children">












  <div class="doc doc-object doc-function">



<h4 id="psp.encoder.ToStyle.forward" class="doc doc-heading">
forward


</h4>
<div class="highlight"><pre><span></span><code><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>Convert feature maps <code>x</code> to one <span class="arithmatex">\(W+\)</span> style vector.</p>

        <details class="quote">
          <summary>Source code in <code>psp/encoder.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert feature maps `x` to one $W+$ style vector.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_channel</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="psp.loss" class="doc doc-heading">
        <code>loss</code>



</h2>

    <div class="doc doc-contents ">

      <p>pSp loss functions</p>



  <div class="doc doc-children">








  <div class="doc doc-object doc-class">



<h3 id="psp.loss.IDLoss" class="doc doc-heading">
          <code>IDLoss</code>



</h3>
<div class="highlight"><pre><span></span><code><span class="n">IDLoss</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
        <p class="doc doc-class-bases">
          Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>




      <p>ID(entity) loss using pretrained ArcFace network.</p>

            <details class="quote">
              <summary>Source code in <code>psp/loss.py</code></summary>
              <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ID(entity) loss using pretrained ArcFace network.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">facenet</span> <span class="o">=</span> <span class="n">Backbone</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">facenet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">face_pool</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">112</span><span class="p">,</span> <span class="mi">112</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">facenet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</code></pre></div>
</td></tr></table>
            </details>



  <div class="doc doc-children">










  <div class="doc doc-object doc-function">



<h4 id="psp.loss.IDLoss.extract_feats" class="doc doc-heading">
extract_feats


</h4>
<div class="highlight"><pre><span></span><code><span class="n">extract_feats</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>Extracts ArcFace features.</p>

        <details class="quote">
          <summary>Source code in <code>psp/loss.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">extract_feats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extracts ArcFace features.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">35</span><span class="p">:</span><span class="mi">223</span><span class="p">,</span> <span class="mi">32</span><span class="p">:</span><span class="mi">220</span><span class="p">]</span>  <span class="c1"># Crop interesting region?!</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">face_pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x_feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">facenet</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_feats</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h4 id="psp.loss.IDLoss.forward" class="doc doc-heading">
forward


</h4>
<div class="highlight"><pre><span></span><code><span class="n">forward</span><span class="p">(</span><span class="n">y_hat</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>Calculates the ID loss.</p>

        <details class="quote">
          <summary>Source code in <code>psp/loss.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the ID loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_feats</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Otherwise use the feature from there</span>
    <span class="n">y_hat_feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extract_feats</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
    <span class="n">y_feats</span> <span class="o">=</span> <span class="n">y_feats</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="n">diff_target</span> <span class="o">=</span> <span class="n">y_hat_feats</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y_feats</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">diff_target</span>

    <span class="k">return</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">n_samples</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h3 id="psp.loss.RegLoss" class="doc doc-heading">
          <code>RegLoss</code>



</h3>
<div class="highlight"><pre><span></span><code><span class="n">RegLoss</span><span class="p">(</span><span class="n">latent_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">
        <p class="doc doc-class-bases">
          Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>




      <p>Regularization loss. Calculates the l2 distance from latent average.</p>

            <details class="quote">
              <summary>Source code in <code>psp/loss.py</code></summary>
              <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_avg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Regularization loss. Calculates the l2 distance from latent average.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">latent_avg</span> <span class="o">=</span> <span class="n">latent_avg</span>
</code></pre></div>
</td></tr></table>
            </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-function">



<h4 id="psp.loss.RegLoss.forward" class="doc doc-heading">
forward


</h4>
<div class="highlight"><pre><span></span><code><span class="n">forward</span><span class="p">(</span><span class="n">latent</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span>
</code></pre></div>

    <div class="doc doc-contents ">

      <p>Calculates the regularization loss.</p>

        <details class="quote">
          <summary>Source code in <code>psp/loss.py</code></summary>
          <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the regularization loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">excess_latent</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">latent</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_avg</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span><span class="n">latent</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_avg</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">excess_latent</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span> <span class="o">/</span> <span class="n">excess_latent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
</td></tr></table>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>










  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">



<h2 id="psp.ranger" class="doc doc-heading">
        <code>ranger</code>



</h2>

    <div class="doc doc-contents ">

      <p>Ranger Optimizer</p>



  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h3 id="psp.ranger.Ranger" class="doc doc-heading">
          <code>Ranger</code>



</h3>
<div class="highlight"><pre><span></span><code><span class="n">Ranger</span><span class="p">(</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">k</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
    <span class="n">N_sma_threshhold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">use_gc</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">gc_conv_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
        <p class="doc doc-class-bases">
          Bases: <code><span title="torch.optim.optimizer.Optimizer">Optimizer</span></code></p>




      <p>(Ranger Optimizer)[https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer].</p>

            <details class="quote">
              <summary>Source code in <code>psp/ranger.py</code></summary>
              <table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>  <span class="c1"># lr</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">k</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
    <span class="n">N_sma_threshhold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># Ranger options</span>
    <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># Adam options</span>
    <span class="n">use_gc</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">gc_conv_only</span><span class="o">=</span><span class="kc">False</span>
    <span class="c1"># Gradient centralization on or off, applied to conv layers only or conv + fc layers</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    (Ranger Optimizer)[https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer].</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># parameter checks</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid slow update rate: </span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">k</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid lookahead steps: </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">lr</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid Learning Rate: </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">eps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid eps: </span><span class="si">{</span><span class="n">eps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># parameter comments:</span>
    <span class="c1"># beta1 (momentum) of .95 seems to work better than .90...</span>
    <span class="c1"># N_sma_threshold of 5 seems better in testing than 4.</span>
    <span class="c1"># In both cases, worth testing on your dataset (.90 vs .95, 4 vs 5) to make sure which works best for you.</span>

    <span class="c1"># prep defaults and init torch.optim base</span>
    <span class="n">defaults</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
        <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
        <span class="n">step_counter</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">,</span>
        <span class="n">N_sma_threshhold</span><span class="o">=</span><span class="n">N_sma_threshhold</span><span class="p">,</span>
        <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span>

    <span class="c1"># adjustable threshold</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">N_sma_threshhold</span> <span class="o">=</span> <span class="n">N_sma_threshhold</span>

    <span class="c1"># look ahead params</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="c1"># radam buffer for state</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">radam_buffer</span> <span class="o">=</span> <span class="p">[[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

    <span class="c1"># gc on or off</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_gc</span> <span class="o">=</span> <span class="n">use_gc</span>

    <span class="c1"># level of gradient centralization</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gc_gradient_threshold</span> <span class="o">=</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">gc_conv_only</span> <span class="k">else</span> <span class="mi">1</span>
</code></pre></div>
</td></tr></table>
            </details>



  <div class="doc doc-children">


















  </div>

    </div>

  </div>






  </div>

    </div>

  </div>




  </div>

    </div>

  </div>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../utils/" class="md-footer__link md-footer__link--prev" aria-label="Previous: utils" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              utils
            </div>
          </div>
        </a>
      
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.instant", "navigation.expand", "search.suggest"], "search": "../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.748e2769.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js"></script>
      
    
  </body>
</html>