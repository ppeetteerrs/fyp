{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images from each class: 100%|██████████| 5/5 [00:04<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.config import CONFIG\n",
    "CONFIG.PSP_USE_MEAN = True\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from psp.pSp_pure import pSp\n",
    "from utils.dataset import MulticlassImageDataset\n",
    "from pathlib import Path\n",
    "from utils.utils import repeat\n",
    "import torch.nn.functional as F\n",
    "\n",
    "output_dir = Path(\"output/paper/mixed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "dataset = MulticlassImageDataset(\n",
    "    [\"input/data/covid_ct_pneumonia/train\"],\n",
    "    [\"lung\", \"localizer\", \"bones\", \"drr\", \"soft\"],\n",
    ")\n",
    "dataloader = repeat(DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=2,\n",
    "    shuffle=True,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"output/psp_pure_pneumonia_chosen_softer/checkpoint/160000.pt\", map_location=\"cuda:0\")\n",
    "net = pSp(ckpt).to(\"cuda:0\")\n",
    "net.latent_avg = net.latent_avg.to(\"cuda:0\") if net.latent_avg is not None else None\n",
    "net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:55<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(list(range(2000))):\n",
    "    with torch.no_grad():\n",
    "        batch = next(dataloader)\n",
    "        img_in = batch[\"lung\"].to(\"cuda:0\")\n",
    "        img_in1 = img_in[0].unsqueeze(0)\n",
    "        img_in2 = img_in[1].unsqueeze(0)\n",
    "\n",
    "        img_out1, codes1 = net(img_in1)\n",
    "        img_out2, codes2 = net(img_in2)\n",
    "\n",
    "        code_7 = torch.concat([codes1[:,:7,:], codes2[:,7:,:]], dim=1)\n",
    "        code_mean = (codes1 + codes2) / 2\n",
    "\n",
    "        img_7 = net.decoder([code_7], return_latents=False, input_type=\"w_plus\", noises=None)\n",
    "        img_7 = F.interpolate(img_7, size=(512, 512), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        img_mean = net.decoder([code_mean], return_latents=False, input_type=\"w_plus\", noises=None)\n",
    "        img_mean = F.interpolate(img_mean, size=(512, 512), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        img1 = torch.concat([img_in1, img_out1], dim=3)\n",
    "        img2 = torch.concat([img_in2, img_out2], dim=3)\n",
    "        img_original = torch.concat([img1, img2], dim=2)\n",
    "        img = torch.concat([img_original, img_mean, img_7], dim=3)\n",
    "\n",
    "    save_image(\n",
    "        img,\n",
    "        str(output_dir / f\"{str(idx).zfill(6)}.png\"),\n",
    "        nrow=1,\n",
    "        normalize=True,\n",
    "        value_range=(-1, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a2f233191b82b47233b539c7573f64d79f81d06fd7b9f837f44e82bffd665fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('user')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
